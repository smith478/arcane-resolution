{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f54552-06c3-4746-b373-d32db0c0f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO also use huggingface for running the model and test chexagent 8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f72c426-7a65-4153-9a95-03f505764ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import base64\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dbd805-44b0-4303-91e7-d35a8c5a07aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_radiology_findings(image_path):\n",
    "    \"\"\"\n",
    "    Generate initial findings from a radiograph image.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the radiograph image\n",
    "    \n",
    "    Returns:\n",
    "        str: Detailed findings from the radiograph\n",
    "    \"\"\"\n",
    "    # Ensure the image exists\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "    \n",
    "    # Convert image to base64 for Ollama\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        encoded_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "    # Prompt for detailed radiograph analysis\n",
    "    prompt = \"\"\"\n",
    "    You are a radiologist analyzing a medical image. Please provide:\n",
    "    - A detailed description of the image\n",
    "    - Specific anatomical observations\n",
    "    - Potential abnormalities or areas of concern\n",
    "    - Suggested follow-up or additional views if necessary\n",
    "    \n",
    "    Provide a comprehensive, professional medical interpretation.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model='llama3.2-vision',\n",
    "            messages=[\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': prompt,\n",
    "                    'images': [encoded_image]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return response['message']['content']\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error generating findings: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcf197c-0365-4fb8-a699-3302835bda43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_radiology_report(image_path, findings):\n",
    "    \"\"\"\n",
    "    Generate conclusions and recommendations based on findings.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the radiograph image\n",
    "        findings (str): Detailed findings from the initial analysis\n",
    "    \n",
    "    Returns:\n",
    "        str: Conclusions and recommendations section of the radiology report\n",
    "    \"\"\"\n",
    "    # Ensure the image exists\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "    \n",
    "    # Convert image to base64 for Ollama\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        encoded_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "    # Prompt for conclusions and recommendations\n",
    "    prompt = f\"\"\"\n",
    "    You are a radiologist preparing a comprehensive report. \n",
    "    \n",
    "    Findings from initial analysis:\n",
    "    {findings}\n",
    "    \n",
    "    Based on these findings, please provide:\n",
    "    - Clear, concise conclusions about the radiographic findings\n",
    "    - Specific medical recommendations\n",
    "    - Suggested next steps for patient care\n",
    "    - Any additional diagnostic tests or specialist consultations that may be warranted\n",
    "    \n",
    "    Provide a professional, structured medical recommendation section.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model='llama3.2-vision',\n",
    "            messages=[\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': prompt,\n",
    "                    'images': [encoded_image]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return response['message']['content']\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error generating recommendations: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59db54cf-b98e-4668-b8c4-f67d49b07bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Example usage of the radiology assistant functions\n",
    "    \"\"\"\n",
    "    # Replace with the path to your radiograph\n",
    "    image_path = 'path/to/your/radiograph.jpg'\n",
    "    \n",
    "    try:\n",
    "        # Generate initial findings\n",
    "        findings = generate_radiology_findings(image_path)\n",
    "        print(\"Initial Findings:\")\n",
    "        print(findings)\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "        \n",
    "        # Generate conclusions and recommendations\n",
    "        recommendations = generate_radiology_report(image_path, findings)\n",
    "        print(\"Conclusions and Recommendations:\")\n",
    "        print(recommendations)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9cd41b-9b17-42bb-96f5-2c899c3a6663",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
